{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Face Detection New.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT LIBRARIES**"
      ],
      "metadata": {
        "id": "2ZHy2afLjBeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "u9lXHyR7fRIq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ],
      "metadata": {
        "id": "2CLHn0YqfcqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3452c0fb-49c9-4655-ebde-f67bf0e70791"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOUNT GOOGLE DRIVE FILES**"
      ],
      "metadata": {
        "id": "rYFWFjbCjJev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "id": "Dnupobd3fcty",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f3df0621-788f-4530-d807-e40326772ce3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACCESS THE DATASET**"
      ],
      "metadata": {
        "id": "2r0IRfGJjPwx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base_dir = '/content/drive/My Drive/Face Detection Project'\r\n",
        "train_dir = os.path.join(base_dir, 'Train')\r\n",
        "val_dir = os.path.join(base_dir,'Validation')\r\n",
        "train_face_dir = os.path.join(train_dir, 'Face')\r\n",
        "train_no_face_dir = os.path.join(train_dir, 'New No Face')\r\n",
        "val_face_dir = os.path.join(val_dir, \"Face\")\r\n",
        "val_no_face_dir = os.path.join(val_dir, \"New No Face\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "P71086BzfcxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(str(len(os.listdir(train_face_dir))) + ' training examples of Faces')\r\n",
        "print(str(len(os.listdir(train_no_face_dir))) + ' training examples of No Faces')\r\n",
        "train_total = len(os.listdir(train_face_dir)) + len(os.listdir(train_no_face_dir))\r\n",
        "print(str(train_total) + ' training examples')\r\n",
        "print(str(len(os.listdir(val_face_dir))) + ' validation examples of Faces')\r\n",
        "print(str(len(os.listdir(val_no_face_dir))) + ' validation examples of No Faces')\r\n",
        "val_total = len(os.listdir(val_face_dir)) + len(os.listdir(val_no_face_dir))\r\n",
        "print(str(val_total) + ' validation examples')\r\n",
        "total = train_total + val_total\r\n",
        "print('Total ' + str(total) + ' examples')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6278 training examples of Faces\n",
            "6068 training examples of No Faces\n",
            "12346 training examples\n",
            "1221 validation examples of Faces\n",
            "1167 validation examples of No Faces\n",
            "2388 validation examples\n",
            "Total 14734 examples\n"
          ]
        }
      ],
      "metadata": {
        "id": "sS4TTIc6fcz0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "fda1b803-3aa0-450f-d4fb-f4103bc46f5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING AND GENERATING BATCHES FOR TRAINING**"
      ],
      "metadata": {
        "id": "0V-Tn1fRjUqW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ht = 420\r\n",
        "wd = 300\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "def center(img):\r\n",
        "    img = np.array(img)  \r\n",
        "    img = cv2.resize(img, (wd, ht))\r\n",
        "    img = img/255.0\r\n",
        "    img[:,:,0] -= 0.5519912\r\n",
        "    # img[:,:,0] /= 0.3125070\r\n",
        "    img[:,:,1] -= 0.4811025\r\n",
        "    # img[:,:,1] /= 0.2979582\r\n",
        "    img[:,:,2] -= 0.4498843\r\n",
        "    # img[:,:,2] /= 0.2945640\r\n",
        "    return img\r\n",
        "\r\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,rotation_range=30,\r\n",
        "                                                                brightness_range=[0.8, 1.2], preprocessing_function=center)\r\n",
        "\r\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=center)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SjeuB5oVfc24"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_gen = train_datagen.flow_from_directory(train_dir, \r\n",
        "                                              batch_size = batch_size, \r\n",
        "                                              subset = 'training',\r\n",
        "                                              target_size = (ht, wd),\r\n",
        "                                              class_mode = 'binary',\r\n",
        "                                              shuffle = True)\r\n",
        "\r\n",
        "val_gen = val_datagen.flow_from_directory(val_dir, \r\n",
        "                                          batch_size = batch_size, \r\n",
        "                                          subset = None,\r\n",
        "                                          target_size = (ht, wd),\r\n",
        "                                          class_mode = 'binary',\r\n",
        "                                          shuffle = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12346 images belonging to 2 classes.\n",
            "Found 2388 images belonging to 2 classes.\n"
          ]
        }
      ],
      "metadata": {
        "id": "olawtgbmfc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bcbf0d0e-49cf-4928-8977-9b38e261d229"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def my_activation_fun(x):\r\n",
        "  # return tf.keras.backend.switch(x>0, tf.keras.backend.relu(x), 0)\r\n",
        "  return tf.keras.backend.relu(x, max_value=10, threshold=-1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QZLSeUHjs7Al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def my_activation_fun(x):\r\n",
        "#   return tf.cond(x > 0, lambda: tf.multiply(x, 1), lambda: tf.multiply(x, 0))\r\n",
        "#   # return tf.multiply(x, 0.8)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FP3ox_LPfc87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL ARCHITECTURE**"
      ],
      "metadata": {
        "id": "ZCYvv272jjur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "regularizer = tf.keras.regularizers.l2(l=0)\r\n",
        "regularizer_1 = tf.keras.regularizers.l2(l=0.001)\r\n",
        "init = tf.initializers.glorot_uniform()\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "                                    \r\n",
        "        tf.keras.layers.Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer, input_shape=(ht, wd, 3)),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(16, (5, 5), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(32, (5, 5), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "\r\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(64, (5, 5), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "    \r\n",
        "        tf.keras.layers.Conv2D(96, (3, 3), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),    \r\n",
        "        tf.keras.layers.Conv2D(96, (5, 5), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.2),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),    \r\n",
        "        tf.keras.layers.Conv2D(128, (5, 5), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.2),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(192, (3, 3), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(192, (5, 5), (1, 1), padding='same', activation=my_activation_fun, kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.2),\r\n",
        "\r\n",
        "        \r\n",
        "        tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "        tf.keras.layers.Dense(256, activation = 'relu', kernel_initializer=init, kernel_regularizer= regularizer_1),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Dropout(0.25),\r\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 420, 300, 16)      448       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 420, 300, 16)      64        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 420, 300, 16)      6416      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 420, 300, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 210, 150, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 210, 150, 32)      4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 210, 150, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 210, 150, 32)      25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 210, 150, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 105, 75, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 105, 75, 64)       18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 105, 75, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 105, 75, 64)       102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 105, 75, 64)       256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 52, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 52, 37, 96)        55392     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 52, 37, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 52, 37, 96)        230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 52, 37, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 26, 18, 96)        0         \n",
            "_________________________________________________________________\n",
            "spatial_dropout2d (SpatialDr (None, 26, 18, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 26, 18, 128)       110720    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 26, 18, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 26, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 9, 128)        0         \n",
            "_________________________________________________________________\n",
            "spatial_dropout2d_1 (Spatial (None, 13, 9, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 13, 9, 192)        221376    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 13, 9, 192)        768       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 13, 9, 192)        921792    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 13, 9, 192)        768       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 4, 192)         0         \n",
            "_________________________________________________________________\n",
            "spatial_dropout2d_2 (Spatial (None, 6, 4, 192)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 3,293,009\n",
            "Trainable params: 3,290,385\n",
            "Non-trainable params: 2,624\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "qngdU-m-xIKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16c3535b-46d1-430c-a8c9-7fcbee385cab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPILE MODEL**"
      ],
      "metadata": {
        "id": "PyuAvLkQjooH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "9FZGB4Bcfc_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN MODEL**"
      ],
      "metadata": {
        "id": "9aHCO4xTjrao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def scheduler(epoch):\r\n",
        "  if epoch <= 14:\r\n",
        "    return 0.001\r\n",
        "  elif 14 < epoch <= 30:\r\n",
        "    return 0.0001\r\n",
        "  else:\r\n",
        "    return 0.00005\r\n",
        "\r\n",
        "reduce_lr_1 = tf.keras.callbacks.LearningRateScheduler(scheduler)\r\n",
        "\r\n",
        "#callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\r\n",
        "path = '/content/drive/My Drive/Face Detection Project/Models/model_custom_activation_function_2.h5'\r\n",
        "save_model = tf.keras.callbacks.ModelCheckpoint(path,monitor='val_loss', save_best_only=True, load_weights_on_restart=True)\r\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "reduce_lr_2 = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \r\n",
        "                                                 factor=0.2, \r\n",
        "                                                 patience=2, \r\n",
        "                                                 verbose=0, \r\n",
        "                                                 mode='auto',\r\n",
        "                                                 min_delta=0.0001, \r\n",
        "                                                 cooldown=1,\r\n",
        "                                                 min_lr=0)\r\n",
        "\r\n",
        "history = model.fit_generator(train_gen,\r\n",
        "                              validation_data=val_gen,\r\n",
        "                              steps_per_epoch=386,\r\n",
        "                              shuffle=True, \r\n",
        "                              epochs=30,\r\n",
        "                              validation_steps=75,\r\n",
        "                              callbacks=[save_model, reduce_lr_2])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`load_weights_on_restart` argument is deprecated. Please use `model.load_weights()` for loading weights before the start of `model.fit()`.\n",
            "WARNING:tensorflow:From <ipython-input-11-ef58e5b86960>:30: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "  3/386 [..............................] - ETA: 1:34:52 - loss: 1.3374 - accuracy: 0.5938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/386 [============>.................] - ETA: 1:41:14 - loss: 1.1756 - accuracy: 0.6497"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 13719s 36s/step - loss: 1.0112 - accuracy: 0.6873 - val_loss: 0.9758 - val_accuracy: 0.6185 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "386/386 [==============================] - 466s 1s/step - loss: 0.6667 - accuracy: 0.7603 - val_loss: 0.7234 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "386/386 [==============================] - 450s 1s/step - loss: 0.5297 - accuracy: 0.7956 - val_loss: 0.5401 - val_accuracy: 0.7747 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "386/386 [==============================] - 436s 1s/step - loss: 0.4458 - accuracy: 0.8297 - val_loss: 0.5200 - val_accuracy: 0.8011 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "386/386 [==============================] - 424s 1s/step - loss: 0.4135 - accuracy: 0.8415 - val_loss: 0.6641 - val_accuracy: 0.7286 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "386/386 [==============================] - 428s 1s/step - loss: 0.3938 - accuracy: 0.8532 - val_loss: 0.4673 - val_accuracy: 0.8065 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "386/386 [==============================] - 429s 1s/step - loss: 0.3858 - accuracy: 0.8582 - val_loss: 0.3806 - val_accuracy: 0.8664 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "386/386 [==============================] - 428s 1s/step - loss: 0.3631 - accuracy: 0.8707 - val_loss: 0.4132 - val_accuracy: 0.8367 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "386/386 [==============================] - 432s 1s/step - loss: 0.3477 - accuracy: 0.8819 - val_loss: 0.4161 - val_accuracy: 0.8543 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "386/386 [==============================] - 433s 1s/step - loss: 0.2686 - accuracy: 0.9168 - val_loss: 0.3021 - val_accuracy: 0.8932 - lr: 2.0000e-04\n",
            "Epoch 11/30\n",
            "386/386 [==============================] - 429s 1s/step - loss: 0.2282 - accuracy: 0.9248 - val_loss: 0.3042 - val_accuracy: 0.8911 - lr: 2.0000e-04\n",
            "Epoch 12/30\n",
            "386/386 [==============================] - 428s 1s/step - loss: 0.2119 - accuracy: 0.9285 - val_loss: 0.2745 - val_accuracy: 0.9079 - lr: 2.0000e-04\n",
            "Epoch 13/30\n",
            "386/386 [==============================] - 425s 1s/step - loss: 0.2053 - accuracy: 0.9291 - val_loss: 0.2726 - val_accuracy: 0.9091 - lr: 2.0000e-04\n",
            "Epoch 14/30\n",
            "386/386 [==============================] - 431s 1s/step - loss: 0.2030 - accuracy: 0.9306 - val_loss: 0.2529 - val_accuracy: 0.9171 - lr: 2.0000e-04\n",
            "Epoch 15/30\n",
            "386/386 [==============================] - 436s 1s/step - loss: 0.1850 - accuracy: 0.9392 - val_loss: 0.2541 - val_accuracy: 0.9087 - lr: 2.0000e-04\n",
            "Epoch 16/30\n",
            "386/386 [==============================] - 429s 1s/step - loss: 0.1766 - accuracy: 0.9417 - val_loss: 0.2933 - val_accuracy: 0.9033 - lr: 2.0000e-04\n",
            "Epoch 17/30\n",
            "386/386 [==============================] - 426s 1s/step - loss: 0.1582 - accuracy: 0.9503 - val_loss: 0.2774 - val_accuracy: 0.9087 - lr: 4.0000e-05\n",
            "Epoch 18/30\n",
            "386/386 [==============================] - 427s 1s/step - loss: 0.1414 - accuracy: 0.9563 - val_loss: 0.2379 - val_accuracy: 0.9225 - lr: 4.0000e-05\n",
            "Epoch 19/30\n",
            "386/386 [==============================] - 421s 1s/step - loss: 0.1341 - accuracy: 0.9583 - val_loss: 0.2484 - val_accuracy: 0.9179 - lr: 4.0000e-05\n",
            "Epoch 20/30\n",
            "386/386 [==============================] - 422s 1s/step - loss: 0.1242 - accuracy: 0.9603 - val_loss: 0.2527 - val_accuracy: 0.9104 - lr: 4.0000e-05\n",
            "Epoch 21/30\n",
            " 33/386 [=>............................] - ETA: 6:02 - loss: 0.1096 - accuracy: 0.9640"
          ]
        }
      ],
      "metadata": {
        "id": "-cDLGWEe_50k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "outputId": "181310cc-6f8a-4fec-80c0-b5f2e53eeb61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot training & validation accuracy values\r\n",
        "plt.plot(history.history['acc'])\r\n",
        "plt.plot(history.history['val_acc'])\r\n",
        "plt.title('Model accuracy')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot training & validation loss values\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Model loss')\r\n",
        "plt.ylabel('Loss') \r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "U7B64W_OLR6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE MODEL (IF NO CALLBACK)**"
      ],
      "metadata": {
        "id": "oLl9WNgBjubL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.save('/content/drive/My Drive/Face Detection Project/Models/model.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "gHCNnI_8gN2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST YOUR MODEL HERE**"
      ],
      "metadata": {
        "id": "ShCNiHjuioa3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_dir_1 = os.path.join(base_dir,'Test')\r\n",
        "test_dir = os.path.join(test_dir_1, 'Test_Mask')\r\n",
        "test_dir_file = os.path.join(test_dir,'Mask')\r\n",
        "f = 1\r\n",
        "test_dir_file_name = os.listdir(test_dir_file)\r\n",
        "ht = 150\r\n",
        "wd = 180\r\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\r\n",
        "                                                              samplewise_center=True,\r\n",
        "                                                              samplewise_std_normalization=True)\r\n",
        "test_gen = test_datagen.flow_from_directory(\r\n",
        "                test_dir,\r\n",
        "                target_size=(ht, wd),\r\n",
        "                batch_size= 1,\r\n",
        "                class_mode='binary',\r\n",
        "                shuffle=False)\r\n",
        "\r\n",
        "a = new_model.predict_generator(test_gen)\r\n",
        "#a = np.around(a, 4)\r\n",
        "\r\n",
        "#plt.figure(figsize=(30, 30))\r\n",
        "j = 1\r\n",
        "cnf = 0\r\n",
        "cf = 0\r\n",
        "for i in a:\r\n",
        "    #plt.subplot(10,5,j)\r\n",
        "    #img = mpimg.imread('C:/Face Detection/Dataset/Test_Mask/Mask/'+test_dir_file_name[j-1])\r\n",
        "    #plt.imshow(img)\r\n",
        "    if i > 0.5:\r\n",
        "        cnf += 1\r\n",
        "        #plt.title('No Face '+str(1-i), fontdict={'color':'g'})\r\n",
        "    else:\r\n",
        "        #plt.title('Face '+str(1-i), fontdict={'color':'r'})\r\n",
        "        cf += 1\r\n",
        "        \r\n",
        "    j += 1\r\n",
        "#plt.savefig('C:/Face Detection/Dataset/Test/Face/prediction.jpg')\r\n",
        "print('no. of faces = ' + str(cf))\r\n",
        "print('no. of no faces = ' + str(cnf))\r\n",
        "if f == 0:\r\n",
        "    accuracy = cf/len(a)*100\r\n",
        "else:\r\n",
        "    accuracy = cnf/len(a)*100\r\n",
        "print(accuracy)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2jyI9Y1_gN9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OTHER MODEL ARCHITECTURES**"
      ],
      "metadata": {
        "id": "UiwP6Zd4i4Jz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "regularizer = tf.keras.regularizers.l2(l=0.001)\r\n",
        "init = tf.initializers.he_uniform()\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "                                    \r\n",
        "        tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer, input_shape=(ht, wd, 3)),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(32, (5, 5), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.Dropout(0.1),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.Dropout(0.1),\r\n",
        "\r\n",
        "        tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "        tf.keras.layers.Dense(256, activation = 'relu', kernel_regularizer= regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Dropout(0.25),\r\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "xSDBqbOyiTIw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "regularizer = tf.keras.regularizers.l2(l=0.1)\r\n",
        "init = tf.initializers.he_uniform()\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "                                    \r\n",
        "        tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer, input_shape=(ht, wd, 3)),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(64, (5, 5), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(96, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.Dropout(0.1),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.Dropout(0.1),\r\n",
        "\r\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.Dropout(0.1),\r\n",
        "\r\n",
        "        tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "        tf.keras.layers.Dense(256, activation = 'relu', kernel_regularizer= regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Dropout(0.25),\r\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "4N1VIvx6qH2A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "regularizer = tf.keras.regularizers.l2(l=0)\r\n",
        "regularizer_1 = tf.keras.regularizers.l2(l=0)\r\n",
        "init = tf.initializers.he_uniform()\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "                                    \r\n",
        "        tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer, input_shape=(ht, wd, 3)),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.DepthwiseConv2D(3, (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.DepthwiseConv2D(3, (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "    \r\n",
        "        tf.keras.layers.Conv2D(96, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),    \r\n",
        "        tf.keras.layers.Conv2D(96, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.DepthwiseConv2D(3, (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.2),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),    \r\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.DepthwiseConv2D(3, (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.25),\r\n",
        "        \r\n",
        "        tf.keras.layers.Conv2D(192, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(192, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.DepthwiseConv2D(3, (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.3),\r\n",
        "\r\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.DepthwiseConv2D(3, (1, 1), padding='same', activation='relu', kernel_initializer=init, kernel_regularizer=regularizer),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), (2, 2)),\r\n",
        "        tf.keras.layers.SpatialDropout2D(0.3),\r\n",
        "        \r\n",
        "        tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "        tf.keras.layers.Dense(256, activation = 'relu', kernel_initializer=init, kernel_regularizer= regularizer_1),\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Dropout(0.25),\r\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "qJT9NyrEJgyB"
      }
    }
  ]
}